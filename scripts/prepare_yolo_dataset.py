#!/usr/bin/env python3
"""Convert Pascal VOC XML annotations into YOLO format for training.

- Reads XML+PNG pairs from data/trainingset
- Splits into train/val
- Writes YOLO labels + copies images under data/ml/{images,labels}/{train,val}
- Regenerates data/ml/data.yaml with detected class names

Usage (examples):
  python scripts/prepare_yolo_dataset.py --dry-run
  python scripts/prepare_yolo_dataset.py --clean
  python scripts/prepare_yolo_dataset.py --input-dir data/trainingset --output-dir data/ml --val-ratio 0.2

This keeps Windows-specific concerns out; it should run cross-platform.
"""

from __future__ import annotations

import argparse
import random
import shutil
import xml.etree.ElementTree as ET
from pathlib import Path
from typing import Dict, List, Sequence, Tuple

BBox = Tuple[float, float, float, float]

# Normalize label names to avoid duplicated classes due to typos
CLASS_ALIASES = {
    "kaysha": "kashya",
}


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description="Prepare YOLO dataset from Pascal VOC XML annotations")
    parser.add_argument("--input-dir", type=Path, default=Path("data/trainingset"), help="Folder containing PNG + XML pairs")
    parser.add_argument("--output-dir", type=Path, default=Path("data/ml"), help="Base output folder (images/labels/data.yaml)")
    parser.add_argument("--val-ratio", type=float, default=0.2, help="Validation split ratio")
    parser.add_argument("--seed", type=int, default=42, help="RNG seed for shuffling")
    parser.add_argument("--clean", action="store_true", help="Remove existing images/labels before writing")
    parser.add_argument("--dry-run", action="store_true", help="Only report stats, do not write files")
    return parser.parse_args()


def load_voc_annotation(xml_path: Path) -> Tuple[int, int, List[Tuple[str, BBox]]]:
    tree = ET.parse(xml_path)
    root = tree.getroot()

    size = root.find("size")
    if size is None:
        raise ValueError(f"Missing size in {xml_path}")
    width = int(size.findtext("width", "0"))
    height = int(size.findtext("height", "0"))
    objects: List[Tuple[str, BBox]] = []

    for obj in root.findall("object"):
        name = obj.findtext("name")
        bbox = obj.find("bndbox")
        if name is None or bbox is None:
            continue
        name = CLASS_ALIASES.get(name.strip(), name.strip())
        xmin = float(bbox.findtext("xmin", "0"))
        ymin = float(bbox.findtext("ymin", "0"))
        xmax = float(bbox.findtext("xmax", "0"))
        ymax = float(bbox.findtext("ymax", "0"))
        objects.append((name.strip(), (xmin, ymin, xmax, ymax)))

    return width, height, objects


def voc_bbox_to_yolo(bbox: BBox, img_w: int, img_h: int) -> BBox:
    xmin, ymin, xmax, ymax = bbox
    # Clamp to image bounds to avoid invalid values
    xmin = max(0.0, min(xmin, img_w))
    xmax = max(0.0, min(xmax, img_w))
    ymin = max(0.0, min(ymin, img_h))
    ymax = max(0.0, min(ymax, img_h))

    cx = ((xmin + xmax) / 2.0) / img_w
    cy = ((ymin + ymax) / 2.0) / img_h
    w = (xmax - xmin) / img_w
    h = (ymax - ymin) / img_h
    return cx, cy, w, h


def write_label_file(label_path: Path, yolo_objects: Sequence[Tuple[int, BBox]]) -> None:
    lines = [f"{cls} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}" for cls, (cx, cy, w, h) in yolo_objects]
    label_path.parent.mkdir(parents=True, exist_ok=True)
    label_path.write_text("\n".join(lines), encoding="utf-8")


def write_data_yaml(output_dir: Path, classes: Sequence[str]) -> None:
    yaml_lines = [
        "# Auto-generated by prepare_yolo_dataset.py",
        f"path: {output_dir.as_posix()}",
        "train: images/train",
        "val: images/val",
        f"nc: {len(classes)}",
        "names:",
    ]
    for idx, name in enumerate(classes):
        yaml_lines.append(f"  {idx}: '{name}'")

    (output_dir / "data.yaml").write_text("\n".join(yaml_lines) + "\n", encoding="utf-8")


def main() -> None:
    args = parse_args()
    rng = random.Random(args.seed)

    xml_files = sorted(args.input_dir.glob("*.xml"))
    if not xml_files:
        raise FileNotFoundError(f"No XML annotations found in {args.input_dir}")

    # Build class list from all annotations
    classes = []
    class_set = set()
    samples: Dict[Path, Dict] = {}

    for xml_path in xml_files:
        img_path = xml_path.with_suffix(".png")
        if not img_path.exists():
            raise FileNotFoundError(f"Image missing for {xml_path.name}: {img_path}")
        w, h, objects = load_voc_annotation(xml_path)
        samples[xml_path] = {"img_path": img_path, "size": (w, h), "objects": objects}
        for name, _ in objects:
            if name not in class_set:
                class_set.add(name)
                classes.append(name)

    classes_sorted = sorted(classes)
    class_to_idx = {name: idx for idx, name in enumerate(classes_sorted)}

    # Shuffle and split
    all_items = list(samples.items())
    rng.shuffle(all_items)
    split_idx = int(len(all_items) * (1.0 - args.val_ratio))
    train_items = all_items[:split_idx]
    val_items = all_items[split_idx:]

    print("Dataset summary")
    print(f"  Samples   : {len(all_items)} (train={len(train_items)}, val={len(val_items)})")
    print(f"  Classes   : {len(classes_sorted)} -> {classes_sorted}")

    if args.dry_run:
        print("Dry-run: no files written")
        return

    # Optionally clean existing output
    if args.clean:
        for sub in ["images", "labels"]:
            target = args.output_dir / sub
            if target.exists():
                shutil.rmtree(target)

    # Prepare directories
    (args.output_dir / "images" / "train").mkdir(parents=True, exist_ok=True)
    (args.output_dir / "images" / "val").mkdir(parents=True, exist_ok=True)
    (args.output_dir / "labels" / "train").mkdir(parents=True, exist_ok=True)
    (args.output_dir / "labels" / "val").mkdir(parents=True, exist_ok=True)

    def process_split(items: List[Tuple[Path, Dict]], split: str) -> None:
        for xml_path, meta in items:
            img_path: Path = meta["img_path"]
            w, h = meta["size"]
            objects = meta["objects"]

            yolo_objects = []
            for name, bbox in objects:
                cls_idx = class_to_idx[name]
                yolo_bbox = voc_bbox_to_yolo(bbox, w, h)
                yolo_objects.append((cls_idx, yolo_bbox))

            # Copy image
            dst_img = args.output_dir / "images" / split / img_path.name
            shutil.copy2(img_path, dst_img)

            # Write label
            dst_label = args.output_dir / "labels" / split / (img_path.stem + ".txt")
            write_label_file(dst_label, yolo_objects)

    process_split(train_items, "train")
    process_split(val_items, "val")

    write_data_yaml(args.output_dir, classes_sorted)

    print("Wrote YOLO dataset:")
    print(f"  images/train : {(args.output_dir / 'images/train').as_posix()}")
    print(f"  images/val   : {(args.output_dir / 'images/val').as_posix()}")
    print(f"  labels/*     : {(args.output_dir / 'labels').as_posix()}")
    print(f"  data.yaml    : {(args.output_dir / 'data.yaml').as_posix()}")


if __name__ == "__main__":
    main()
